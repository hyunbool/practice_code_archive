{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laliga  파일 길이 :  244\n",
      "laliga  :  ./image/train/laliga/frames15875.jpg\n",
      "bundesliga  파일 길이 :  220\n",
      "bundesliga  :  ./image/train/bundesliga/bundesliga(97).jpg\n",
      "kleague  파일 길이 :  317\n",
      "kleague  :  ./image/train/kleague/kleague(229).jpg\n",
      "ligue1  파일 길이 :  301\n",
      "ligue1  :  ./image/train/ligue1/OM vs Strasbourg du 26092018 - 1e_re mi-temps.mp4_001621920.jpg\n",
      "seriea  파일 길이 :  317\n",
      "seriea  :  ./image/train/seriea/serieA(190).jpg\n",
      "ok 1399\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "caltech_dir = \"./image/train\"\n",
    "categories = ['laliga', 'bundesliga', 'kleague', 'ligue1', 'seriea', 'playing']\n",
    "nb_classes = len(categories)\n",
    "\n",
    "image_w = 220\n",
    "image_h = 200\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = caltech_dir + \"/\" + cat\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(cat, \" : \", f)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 이면 airplanes\n",
    "#0 1 0 0 이면 buddha 이런식\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save(\"./numpy_data/multi_image_data.npy\", xy)\n",
    "\n",
    "print(\"ok\", len(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok 1399\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 이면 airplanes\n",
    "#0 1 0 0 이면 buddha 이런식\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save(\"./numpy_data/multi_image_data.npy\", xy)\n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import models, layers\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras import Input\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 64, 64, 3)\n",
      "(1049, 64, 64, 3)\n",
      "1049\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = np.load('./numpy_data/multi_image_data.npy', allow_pickle=True)\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1399 images belonging to 5 classes.\n",
      "Found 1399 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#일반화\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4096)              8392704   \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 33,601,349\n",
      "Trainable params: 33,601,349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_dir = './model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_path = model_dir + '/multi_img_classification.model'\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
    "\"\"\"\n",
    "pre_trained_vgg = VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "pre_trained_vgg.trainable = True\n",
    "pre_trained_vgg.summary()\n",
    "\n",
    "additional_model = models.Sequential()\n",
    "additional_model.add(pre_trained_vgg)\n",
    "additional_model.add(layers.Flatten())\n",
    "additional_model.add(layers.Dense(4096, activation='relu'))\n",
    "additional_model.add(layers.Dense(2048, activation='relu'))\n",
    "additional_model.add(layers.Dense(1024, activation='relu'))\n",
    "additional_model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "additional_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_dir = './model'\n",
    " \n",
    " \n",
    "additional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1049 samples, validate on 350 samples\n",
      "Epoch 1/50\n",
      " 192/1049 [====>.........................] - ETA: 51s - loss: 10.0992 - acc: 0.2604"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-e4d44b897d29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#데이터셋이 충분하시면 이렇게 하시지 마시고 validation_split=0.2 이렇게 하셔서 테스트 셋으로 나누시길 권장합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madditional_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#데이터셋이 충분하시면 이렇게 하시지 마시고 validation_split=0.2 이렇게 하셔서 테스트 셋으로 나누시길 권장합니다.\n",
    "history = additional_model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 752us/step\n",
      "정확도 : 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU9b3/8ddnkpCVNYnBggp6lSqLRCOSIhq0VlCr1A39uVfl9l5tabVc8bYuD2y99WqV9rq0WK1iqcvVq3KVirfIgEIUgUZlU5ZqiShIgJCFLJP5/v44kxBCMlnIZELO+/l4zGPmnDnLJ99M5p2zfY855xAREf8KxLsAERGJLwWBiIjPKQhERHxOQSAi4nMKAhERn0uMdwHtlZWV5YYMGdKheSsqKkhPT+/cgnoYtVF0ap/WqY2ii1f7rFy5codzLru59w65IBgyZAgrVqzo0LzBYJCCgoLOLaiHURtFp/Zpndoouni1j5l93tJ72jUkIuJzCgIREZ9TEIiI+Nwhd4xARLqX2tpaiouLqaqqAqBv376sW7cuzlV1X7Fun5SUFAYPHkxSUlKb51EQiMhBKS4upnfv3gwZMgQzo6ysjN69e8e7rG4rlu3jnKOkpITi4mKGDh3a5vm0a0hEDkpVVRWZmZmYWbxL8T0zIzMzs2HrrK18EwSFhTB37pEUFsa7EpGeRyHQfXTkd+GLXUOFhTBhAlRXD2XuXFi4EPLz412ViEj3ELMtAjN7ysy2m9nqFt43M/utmW00s4/M7KRY1RIMQk0NgFFT4w2LiIgnlruGngYmRnl/EnBs5DEVeDxWhRQUQP0B9KQkb1hE/CkjI6PTljVr1iwqKyujTjNkyBB27NjRaeuMhZgFgXNuCbAzyiQXAnOc5z2gn5kdHota8vPhP/7De/2b32i3kEjcFRZ6f5SH+EG7tgTBoSCexwgGAVsaDRdHxn3ZdEIzm4q31UBOTg7BDuzbSUvrDZzMjh0fEwyWdKReXygvL+9Q+/qF2udAffv2paysDIDk228n9aOPCEU7YLlnDwmrV0M4DIEAdSNGQJ8+LU4eHjmS6vvvb/H9u+++m0GDBjF16lQA7rvvPhITE3nnnXfYvXs3tbW13HnnnZx33nkN89TX29RXX33FddddR1lZGaFQiIcffphvfetbLFy4kPvuu4+amhqGDh3KY489xrPPPsvWrVs544wzyMzM5I033mh2mc45ysvLSU5O5pFHHmHOnDmYGddccw0333wzFRUVXHvttWzdupW6ujr+7d/+jYsvvpi7776b+fPnk5iYyJlnnskvf/nLltu0iaqqqnZ9Tg+Jg8XOudnAbIC8vDzXkQ6b6jssPfzwkdo1FIU6DItO7XOgdevW7TsvvlcvQmYkJiS0PENZmRcCAOEwiWVl0L9/y9P36kWvKOfdX3311fz4xz/mtttuA+C1115jwYIFTJ8+nT59+rBjxw7Gjh3LlClTGs6oaek8/tmzZ3Puuefys5/9jLq6OiorK6muruahhx5i0aJFpKenc//99/PEE09w11138dhjj7F48WKysrJarM/MyMjI4NNPP+XPf/4zixYtIiMjg1NPPZVzzjmHzZs3c+SRR7JgwQIASktLqamp4Y033mD9+vWYGbt3727XtQcpKSnk5ua2efp4BsEXwBGNhgdHxsVE/e/p669jtQYRYdYs9rZ2wVRhIZx1lncGR69eMHfuQe2vzc3NZfv27WzdupWvv/6a/v37M3DgQH7yk5+wZMkSAoEAX3zxBdu2bWPgwIFRl3XKKafw/e9/n9raWiZPnszo0aNZvHgxa9euZdy4cQDU1NSQ34F63333Xb73ve+Rnp5ORkYGF110Ee+88w4TJ07ktttu4/bbb+f8889n/PjxhEIhUlJSuOGGGzj//PM5//zzO9Q2bRXP6wjmAddEzh4aC5Q65w7YLdRZ0tMhKSlMNz9mI9Lz5ed753Dfe2+nnct96aWX8tJLL/HCCy8wZcoU5s6dy9dff83KlSspKioiJyenTRdZnX766SxZsoRBgwZx3XXXMWfOHJxznH322RQVFVFUVMTatWt58sknD7rmescddxyrVq1i5MiR/PznP2fmzJkkJiayfPlyLrnkEl5//XUmTox23s3Bi+Xpo88BhcAwMys2sxvM7Adm9oPIJPOBzcBG4AngX2NVi1cP9OtXoyAQ6Q7y8+GOOzrtzI0pU6bw/PPP89JLL3HppZdSWlrKYYcdRlJSEosWLeLzz1vsin8/n3/+OTk5Odx0003ceOONrFq1irFjx7J06VI2btwIeDeW+fTTTwFvF1NLxxuaGj9+PK+++iqVlZVUVFTwyiuvMH78eLZu3UpaWhpXXXUV06dPZ9WqVZSXl1NaWsq5557Lww8/zIcfftixhmmjmO0acs5d0cr7Drg5VutvTt++tXz9dUpXrlJEusDw4cMpKytj0KBBHH744Vx55ZV897vfZeTIkeTl5fHNb36zTcsJBoM88MADJCUlkZGRwZw5c8jOzubpp5/miiuuoLq6GoBf/OIXHHfccUydOpWJEyfyjW98g0WLFkVd9kknncR1113HhAkTCAQC3HjjjeTm5jYczwgEAiQlJfH4449TVlbGhRdeSFVVFc45HnrooYNuo2jM+z4+dOTl5bmO3qEsL28nSUkDDvUz1mJKB0OjU/scaN26dRx//PENw+p0LrquaJ+mvxMAM1vpnMtrbnrf9DUE3haBdg2JiOzvkDh9tLMoCEQE4OOPP+bqq6/eb1xycjLvv/9+h5d56qmnNuw6qvfss88ycuTIDi+zq/guCHbvhtrafV1OiIj/jBw5kqKiok5d5sGESLz5btcQQIkuLBYRaeCrIOjXzwsC7R4SEdnHV0FQv0Wgq4tFRPbxZRBoi0BEZB8FgYgc0nbv3s1jjz3W7vnOPfdcdu/eHYOK9ikqKmL+/PkxXUdnUBCISJfrzNsRtBQEoVAo6nzz58+nX79+B19AFIdKEPjq9NHEREffvjpGIBIrP/4xrFyZSrReqEtL4aOPGm5HwKhR0Ldvy9OPHg2zZrX8/owZM9i0aROjR48mKSmJlJQU+vfvz/r16/n000+ZPHkyW7ZsoaqqimnTpjXct2DIkCGsWLGC8vJyJk2axGmnncayZcsYNGgQr732Gqmpqc2u77e//S2/+93vSExM5IQTTuD555+noqKCH/7wh6xevZra2lruueceJk2axF133cXevXt59913ueOOO5gyZcoBy9u5cyff//732bx5M2lpacyePZtRo0axePFipk2bBnhdWS9ZsoTy8nKmTJnCnj17CIVCPP7444wfP77lxmkjXwUBeN1Ra4tAJH5KS/e7HQGlpdGDoDW/+tWvWL16NUVFRQSDQc477zxWr17N0KFDAXjqqacYMGAAe/fu5ZRTTuHiiy8mMzNzv2Vs2LCB5557jieeeILLLruMl19+mauuuqrF9f39738nOTm5YdfSL3/5S84880yeeuopdu/ezZgxY/j2t7/NzJkzWbFiBY888kiL9d99993k5uby6quv8vbbb3PNNddQVFTEgw8+yKOPPsq4ceMoLy8nJSWF2bNnc8455+x3v4TO4LsgyM5WEIjEyqxZUFa2N2pfOp18O4IDjBkzpiEEwPsP/pVXXgFgy5YtbNiw4YAgGDp0KKNHjwbg5JNP5rPPPmtx+aNGjeLKK69k8uTJTJ48GYC33nqLefPm8eCDDwLeHcL+8Y9/tKned999l5dffhmAM888k5KSEvbs2cO4ceO49dZbufLKK7nooosYPHhws/dL6Ay+OkYA3haBdg2JxE8Mbkewn/T09IbXwWCQv/71rxQWFvLhhx+Sm5vb7H0JkpOTG14nJCREPb7wxhtvcPPNN7Nq1SpOOeUUQqEQzjlefvnlhnsW/OMf/zig07f2mjFjBn/4wx/Yu3cv48aNY/369c3eL6Ez+DIItEUgEl+deTuCaPcEKC0tpX///qSlpbF+/Xree++9g1pXOBxmy5YtTJgwgfvvv5/S0lLKy8s555xz+K//+i/qe3P+29/+1mpt9caPH8/cuXMBL7iysrLo06cPmzZtYuTIkdx+++2ccsoprF+/vtn7JXQG3wbBIdb7toi0IDMzk3HjxjFixAimT5++33sTJ04kFApx/PHHM2PGDMaOHXtQ66qrq+Oqq65i5MiR5Obm8qMf/Yh+/fpx5513Ultby6hRoxg+fDh33nknABMmTGDt2rWMHj2aF154odll3nPPPaxcuZJRo0YxY8YMnnnmGQBmzZrFiBEjGDVqFElJSUyaNIlgMMiJJ55Ibm4uL7zwQsPB5IPlq/sRBINBli8v4Pbbobzcu32l7E/97Uen9jmQ7kfQProfQTegm9iLiOzPd2cN1QfBjh0wZEhcSxGRbuzmm29m6dKl+42bNm0a119/fYeW98c//pHf/OY3hMNhAgHvf/Bx48bx6KOPHnStB8t3QZCd7T3rgLFI53HOYWbxLqNTdfYX9PXXX8/1118f811DHdndr11DInJQUlJSKCkp6dAXkHQu5xwlJSWkpKS0az7fbRE03jUkIgdv8ODBFBcX83Xkv6uqqqp2fxH5SazbJyUlhcGDB7drHt8FQd++kJCgIBDpLElJSftdyRsMBsnNzY1jRd1bd2wf3+0aCgR0UZmISGO+CwJQNxMiIo35Ngi0RSAi4vFlEKgHUhGRfXwZBNo1JCKyj2+DYOdOqKuLdyUiIvHn2yAIhyHG960WETkkxDQIzGyimX1iZhvNbEYz7x9pZovM7G9m9pGZnRvLeuqpmwkRkX1iFgRmlgA8CkwCTgCuMLMTmkz2c+BF51wucDnwWKzqaUzdTIiI7BPLLYIxwEbn3GbnXA3wPHBhk2kc0Cfyui+wNYb1NFA3EyIi+8Syi4lBwJZGw8XAqU2muQd4y8x+CKQD325uQWY2FZgKkJOTQzAY7FBB5eXlBINBtm9PBvJZuvQT+vX7skPL6qnq20iap/Zpndoouu7YPvHua+gK4Gnn3K/NLB941sxGOOfCjSdyzs0GZoN3h7KO3iGq/u5SlZXe8IABwygoGHYQ5fc8ugNXdGqf1qmNouuO7RPLXUNfAEc0Gh4cGdfYDcCLAM65QiAFyIphTQCkpXkP7RoSEYltEHwAHGtmQ82sF97B4HlNpvkHcBaAmR2PFwRdcghX3UyIiHhiFgTOuRBwC7AAWId3dtAaM5tpZhdEJrsNuMnMPgSeA65zXXR3i+xsnTUkIgIxPkbgnJsPzG8y7q5Gr9cC42JZQ0u0RSAi4vHllcWgIBARqefbIFAPpCIiHt8GQVYWlJVBdXW8KxERiS9fBwFoq0BExLdBoI7nREQ8vg0CdTwnIuLxfRBoi0BE/E5BoCAQEZ/zbRAMGABmCgIREd8GQWIi9O+vYwQiIr4NAtDVxSIi4PMg0NXFIiI+D4KsLO0aEhHxfRBoi0BE/E5BsAO65g4IIiLdk6+DIDsbamu9zudERPzK10GgbiZERBQEgI4TiIi/+ToI1AOpiIjPg0C7hkREFASAtghExN98HQS9e0NSkoJARPzN10Fgpm4mRER8HQSgbiZERBQE6mZCRHzO90GgXUMi4ne+DwLtGhIRv1MQZMGuXRAKxbsSEZH4UBBEriXYuTO+dYiIxIvvg0DdTIiI38U0CMxsopl9YmYbzWxGC9NcZmZrzWyNmf05lvU0R91MiIjfJcZqwWaWADwKnA0UAx+Y2Tzn3NpG0xwL3AGMc87tMrPDYlVPS9TNhIj4XSy3CMYAG51zm51zNcDzwIVNprkJeNQ5twvAObc9hvU0S7uGRMTvYrZFAAwCtjQaLgZObTLNcQBmthRIAO5xzr3ZdEFmNhWYCpCTk0MwGOxQQeXl5QfMW1NjwBksX/53hg37vEPL7UmaayPZR+3TOrVRdN2xfWIZBG1d/7FAATAYWGJmI51zuxtP5JybDcwGyMvLcwUFBR1aWTAYpLl5e/eG3r2HUlAwtEPL7UlaaiPxqH1apzaKrju2Tyx3DX0BHNFoeHBkXGPFwDznXK1z7u/Ap3jB0KXUzYSI+Fksg+AD4FgzG2pmvYDLgXlNpnkVb2sAM8vC21W0OYY1NUvdTIiIn8UsCJxzIeAWYAGwDnjRObfGzGaa2QWRyRYAJWa2FlgETHfOlcSqppaomwkR8bOYHiNwzs0H5jcZd1ej1w64NfKIm6wsWL06nhWIiMSP768sBu0aEhF/UxDgbRFUVnoPERG/URCgq4tFxN8UBCgIRMTfFATs62ZCZw6JiB8pCNAWgYj4W5uCwMymmVkf8zxpZqvM7DuxLq6rKAhExM/aukXwfefcHuA7QH/gauBXMauqi/XvD4GAgkBE/KmtQWCR53OBZ51zaxqNO+QFApCZqWMEIuJPbQ2ClWb2Fl4QLDCz3kA4dmV1PXU8JyJ+1dYuJm4ARgObnXOVZjYAuD52ZXU9BYGI+FVbtwjygU+cc7vN7Crg50Bp7MrqetnZ2jUkIv7U1iB4HKg0sxOB24BNwJyYVRUH2iIQEb9qaxCEIj2FXgg84px7FOgdu7K6XlYWlJRAuEcd+RARaV1bg6DMzO7AO230DTMLAEmxK6vrZWdDXR2U9qgdXiIirWtrEEwBqvGuJ/gK77aTD8Ssqjiov6hMxwlExG/aFASRL/+5QF8zOx+ocs71uGMEoOMEIuI/be1i4jJgOXApcBnwvpldEsvCupqCQET8qq3XEfwMOMU5tx3AzLKBvwIvxaqwrqYeSEXEr9p6jCBQHwIRJe2Y95CgLQIR8au2bhG8aWYLgOciw1NoclP6Q11aGqSkKAhExH/aFATOuelmdjEwLjJqtnPuldiV1fXMdBN7EfGntm4R4Jx7GXg5hrXEXVaWjhGIiP9EDQIzKwNcc28BzjnXJyZVxYm6mRARP4oaBM65HtWNRGuysmDz5nhXISLStXrUmT8HSz2QiogfKQgaycqCPXugpibelYiIdB0FQSP11xKUlMS3DhGRrqQgaKT+6mIdMBYRP1EQNKIeSEXEj2IaBGY20cw+MbONZjYjynQXm5kzs7xY1tMadTMhIn4UsyAwswTgUWAScAJwhZmd0Mx0vYFpwPuxqqWttGtIRPwollsEY4CNzrnNzrka4Hm8W102dS9wP1AVw1raZMAA71m7hkTET9rcxUQHDAK2NBouBk5tPIGZnQQc4Zx7w8ymt7QgM5sKTAXIyckhGAx2qKDy8vJW583IGMeHH24jGNzYoXUc6trSRn6m9mmd2ii67tg+sQyCqCL3PX4IuK61aZ1zs4HZAHl5ea6goKBD6wwGg7Q278CBkJw8mIKCwR1ax6GuLW3kZ2qf1qmNouuO7RPLXUNfAEc0Gh4cGVevNzACCJrZZ8BYYF68DxirB1IR8ZtYBsEHwLFmNtTMegGXA/Pq33TOlTrnspxzQ5xzQ4D3gAuccytiWFOr1AOpiPhNzILAORcCbgEWAOuAF51za8xsppldEKv1Hiz1QCoifhPTYwTOufk0uZOZc+6uFqYtiGUtbVW/a8g572Y1IiI9na4sbiIrC6qrobw83pWIiHQNBUETurpYRPxGQdCEgkBE/EZB0ER9NxM6c0hE/EJB0IS2CETEbxQETSgIRMRvFARN9O0LiYkKAhHxDwVBE2a6ulhE/EVB0AxdXSwifqIgaIaCQET8REHQjOxs7RoSEf9QEDRDWwQi4icKgmZkZcHOnVBXF+9KRERiT0HQjOxsr/fRXbviXYmISOwpCJpRf1GZjhOIiB8oCJqhq4tFxE8UBM1QEIiInygImqEeSEXETxQEzcjM9J61RSAifqAgaEZqKqSnKwhExB8UBC2ov4m9iEhPpyBogXogFRG/UBC0QN1MiIhfKAhaoCAQEb9QELRAPZCKiF8oCFqQlQUVFbB3b7wrERGJLQVBC+qvLi4piW8dIiKxpiBoQf3VxTpOICI9nYKgBeqBVET8QkHQAnU8JyJ+EdMgMLOJZvaJmW00sxnNvH+rma01s4/MbKGZHRXLetpDQSAifhGzIDCzBOBRYBJwAnCFmZ3QZLK/AXnOuVHAS8B/xqqe9howAMy0a0hEer5YbhGMATY65zY752qA54ELG0/gnFvknKuMDL4HDI5hPe2SkOCFgbYIRKSnS4zhsgcBWxoNFwOnRpn+BuAvzb1hZlOBqQA5OTkEg8EOFVReXt6uedPSxrB2bTnB4NoOre9Q1N428hu1T+vURtF1x/aJZRC0mZldBeQBZzT3vnNuNjAbIC8vzxUUFHRoPcFgkPbMe9RREAikUVBwWIfWdyhqbxv5jdqndWqj6Lpj+8Ry19AXwBGNhgdHxu3HzL4N/Ay4wDlXHcN62k09kIqIH8QyCD4AjjWzoWbWC7gcmNd4AjPLBX6PFwLbY1hLh6jjORHxg5gFgXMuBNwCLADWAS8659aY2UwzuyAy2QNABvDfZlZkZvNaWFxc1AeBc/GuREQkdmJ6jMA5Nx+Y32TcXY1efzuW6z9Y2dkQCkFpKfTrF+9qRERiQ1cWR6GLykTEDxQEUSgIRMQPFARR1PdAqjOHRKQnUxBEoS0CEfEDBUEUCgIR8QMFQRQZGdCrl4JARHo2BUEUZrqJvYj0fAqCVujqYhHp6RQErVAQiEhPpyBohXYNiUhP558gKCzkyLlzobCwXbNpi0BEejp/BEFhIZx5JkOffBLOOqtdYZCVBbt3Q21tDOsTEYkjfwRBMAjV1ZhzUF3tDbdR/bUEO3fGpDIRkbjzRxAUFEBKCg4gHIakpDbPqm4mRKSn80cQ5OfDwoV8du21MGwY3H03LF/epll1dbGI9HT+CAKA/Hw+v+46WLwYBg6E886DjRtbnU1BICI9nX+CoF5ODvzlL95txyZOhO3R75BZv2vo2WfbfcKRiMghwX9BAHDccfD667B1K5x/PlRUtDjphg3e8//+b7tPOBIROST4MwgAxo6FF16AlSvhssu8e1I2Y+lS79k52LsXnn6660oUEekK/g0CgO9+Fx57DObPh3/5l2bvUl9QAKmpEIi01OzZcMEFsGZN15YqIhIr/g4CgH/+Z/jZz+APf4CZMw94O3LCEb/4Bbz9Ntx3n3e8edQouOEGKC6OQ80iIp1IQQBw771w7bVwzz3w5JMHvJ2fD3fcARMmeM+bN8O0afCnP8Gxx8KMGbBrV9eXLSLSGRQE4N144Ikn4JxzvC2E+fOjTp6ZCQ89BJ98ApdcAv/5n3DMMfDgg1BV1UU1i4h0EgVBvaQk+O//hhNPhEsvhQ8+aHWWIUO800pXrYJTT4Xp070Tkp55BurqYl+yiEhnUBA01rs3vPEGHHaYd8HZpk1tmm30aO/ShIULvVmvuw5yc+HXv/aOKeiUUxHpzhQETQ0cCG++6fVJNHFiuzoZOvNMr+eK55+HkhL46U+949Cnn+4dhti4sdkTk0RE4kpB0Jxhw7wryIqLW73grKlAAKZM8c5GNfPGhUJw113egeX+/b3AmD7dCwyFg4jEW2K8C+i28vPhuefg4ou9g8iTJnnf4Pn5bZr9rLO83UI1NdCrl3e5Qm2td/3aypXw29967wH07QsnnQQnn7zvsX07LFniXcfQxlWKiHSIgiCayZPh1lu904GWLvX+3T/7bDjtNO+o8LBh3r/5aWkHzFp//UEwuP+X+U03ec81Nd5FafXB0DQc6iUkwFVXebuXjjkGjj4aBg3ad4GbiMjBUhC0ZsAA71s3HPYehYWwYMH+0xxxhBcK9eEQec6v+4J83gEKgP3/re/VyzugnJsLN97ojaut9cLh3nvhlf9xOIy6OsecOcYzz+w/79ChXigcffS+gDjmGG9L4v33O7YlUVgIc+ceSXKytkJEYuFg/sYKCw/8x7KzxDQIzGwi8BsgAfiDc+5XTd5PBuYAJwMlwBTn3GexrKndCgogOXnfPp433/QuK96wwbuQ4NNP9z3/6U+wZ8+ByzCDESO8nk/T0g58pKZCWhpJaWmMTkvjpwPgL1xODUn0opYFP/oLg751JJu+ymDzV6ls/jKVTV+ksPmzZJa+k8Se8oQmK/QOOgwcaPTu7ZWdnOw9N340Hrdrl/ejhUJDeeYZuPNOGD/eOwsqJ8c7ttHSVkhHPqDOQWUlvP3YOt6fv5OzLu5Hwc3DG46rtOZg/ihi+QclHRAKeafdLVmybxdsDxEOe7e63bHD+8z98JYwtbVDeObpMLf8MMDAgd61R1VVXl9mLb3++mtYv95hzpGc7Fi4KKFTP7vmYnSk0swSgE+Bs4Fi4APgCufc2kbT/Cswyjn3AzO7HPiec25KtOXm5eW5FStWdKimYDBIQUFB+2ds6zeHc96/5J98ArNmwauv7jsSfPTR3jdqZeX+j/rfeNNVMpYgBRQQJJ/3Wl4lsJMBbOZoHuJWXuAyHAkYYUYHPmJY6hZqEtO8R0IK1ZZKTSCZGpKpoRfVLomacCIl5cmUVSYAzX8TJyY6sjPDHJYVJifbcVi2IycH9lYZf3g6kVAIEhPhX//fbjLT9rJnVx2lu8PsKYU95UZpeQJ7KhPZs7cXpdXJ7KlJJXzAuQph0pNqSe9VS3pyiPSUOtLTHOlpkJ5hpPcJkN4nkT3VvXjl9STq6ozEBMfUHwQ45hhv/U0fSUn7D2/YAHfcHqY2BEmJ8NCsAKNGebvgAoHmHwkBR4AwH770Kf/30udMnHIUeVd+k0CCtThP08fyP67mnVdLOON7meTfNALw/j9o+jjgczD7Y4Ivl1BwcSb5U0e2/NlrRuN5x940EufY7xEOc8A45+C9p9bw7ms7OeN7A/jWTcNJSPDapy0hXTj7Y/7niQ1cdMMx5E/Oga++gm3bcF9tI/zlNmq/3EHtVyWEvtpB7fZdhLaVULurjOWM4T3GcirvcVKvtVjOYVhWJpY5AMvO8l5nZzU8AodlYYdlY316s3Luepa+voux5w4g94pvNmy8h8Pe9TyNhxuPK3p5IyvfLuWkCf0YceExwP4nbtS/bm7cR69u4r2FlRwxqj/9vjmQHVtrKNlWy47tYXbsMEp2B9hRmsTOimTCrvX9uElWS0pCLakJNaQkRF4n1kZeh9ha3psNFYcDARKo5d4fbOWOx49q4yfBY2YrnXN5zb4XwyDIB+5xzp0TGTK5hkEAAAorSURBVL4DwDn3H42mWRCZptDMEoGvgGwXpai4BEFHFBZ6R4zrtyQWLmw5RMJhLxDqw2HZMrj+em9fUVKSd0HCsGHef05RHoVzNnDWO3c3bEksHD6N/Nwq71+S0lLvuf5RVrZ/uYzlLBZSQxJJ1PIEN/ENvmQbOWznsGaft5FDFanN/kipVNKHPfRhD30pbXjdJ3EvfZP30iellpXlw1hQfXokuOooSHiX3MSPqahOooI0Kkhv9lHCAKpJoaXQOtQZYQwHOMLs29pLoC4yHlyTn/3AYXAE6Ow2SiBEgoVJoG7fM2ESrI46Z+wM92tYZxoVgFFLErX06tQ6upteVJPFjoZHJiWNXu8kK7WC7S6LO6ruJkQiSdTyyoAbOf3Iz0h2VSS40IGp1Wi4cMexnFU5b9/f9g9eIv/xa9pVY7QgiOWuoUHAlkbDxcCpLU3jnAuZWSmQCex3PzAzmwpMBcjJySHYjpvPN1ZeXt7heTuizwMP0K+oiN2jR7OnutrbqmiLww+nz69/vW/e4cO98YnRf119plTz1nuTWBIax+mJS0n+l8sI1s/bVF0diZWVJJaXk1hezlGvvcZf3/g2izmDM1jMMQXJ7MzP5xuRD6K5XVC3A3NrsIYPapiPFxlXrn+A2kiAPDXyboZd3J9A31RCqanUpaXteyT3hUD/hhL+6X93sPih6oYP9zXTvmbId0eAcwSqqkisrCShYhuJFRWR197z318v4eI1v2mY77mhP+Lo0WHqXAJ1dUZdOEAoHGgYDoUD3jiXwKb1qfzbV/9OLYkkEWLmwIcYdGwdzhKoI0C48aNhXAJvf3g0r+0+mzAJBKjjvL6LGH/8373/qsON/ruug7CzfePCULjlWBZWnrYv8FKXMebwjTjMmwfb7zWAc8bKbcfwbtWpOAIYdXwrZQW5h2/2Gs/MmzLyb7qr36KIDK8qPop3K8fgMIw6xqct55TBf28ImATCXuC4hrVjhHmv+FgW7h3fUOuElKXkHb7JmzocoA6vXcPOvPZ1AcIuQJ0LsLrkKHbV9IusM8zw3psZPrIc0noRyEjGMpKxlEQSEx0JCY6EhDCJiY6ihYks+nAILtK2Z+ZuJu+cUOS/b69dqAsTqNxLoKKShMgjULGXwqKBvFl2RsO856X/H2cetZqAeT9PwBwJFvmN1o8LON7adCIvll0Q+X2GuLz3a5z3TysbPpuBSOCaCxOpouG91zfmMbf8YsIkkECI2w5/khsuWUtdRjqhjAzvkZ5OKCOTUPqR1KWlQSDA8WvW8NefnNPw95k28zKWD7+ptW8D7297zRre+kmjv+0Rl3Xud5lzLiYP4BK84wL1w1cDjzSZZjUwuNHwJiAr2nJPPvlk11GLFi3q8LyHjGXLnLvvPu+5vfOlprq6QMC51NS2z79smVvW6wx3n/27W9brjHavd9nvP3L3fWeRW/b7j9pVa4fX2cF5l/3+I5dKhUugxqVS0a56Ozqvb9a5zLnU5JBLsJBLTQ6179d5CP2c3szL3KYbb2z/32dk3g79bUcAK1xL39ctvXGwD7zTZBY0Gr4DuKPJNAuA/MjrRLwtAYu2XAVBDHX0Q3qQH9AOOZh1dnDeZb//yP007+X2/eE3mrfdgXcQ88VznR1po4P6dR5Cbetc/L6H4hUEicBmYCjQC/gQGN5kmpuB30VeXw682NpyFQSxpTaKTu3TOrVRdN0xCGJ2jMB5+/xvifzXnwA85ZxbY2YzIwXNA54EnjWzjcDOSBiIiEgXiul1BM65+cD8JuPuavS6Crg0ljWIiEh06qhARMTnFAQiIj6nIBAR8TkFgYiIz8Wsi4lYMbOvgc87OHsWTa5algOojaJT+7RObRRdvNrnKOdcdnNvHHJBcDDMbIVroa8N8aiNolP7tE5tFF13bB/tGhIR8TkFgYiIz/ktCGbHu4BDgNooOrVP69RG0XW79vHVMQIRETmQ37YIRESkCQWBiIjP+SYIzGyimX1iZhvNbEa86+luzOwzM/vYzIrMrGP3Au1hzOwpM9tuZqsbjRtgZv9nZhsiz/2jLaMna6F97jGzLyKfoyIzOzeeNcabmR1hZovMbK2ZrTGzaZHx3epz5IsgMLME4FFgEnACcIWZnRDfqrqlCc650d3tHOc4ehqY2GTcDGChc+5YYGFk2K+e5sD2AXg48jkaHemB2M9CwG3OuROAscDNke+ebvU58kUQAGOAjc65zc65GuB54MI41yTdnHNuCd59Mhq7EHgm8voZYHKXFtWNtNA+0ohz7kvn3KrI6zJgHd692rvV58gvQTAI2NJouDgyTvZxwFtmttLMpsa7mG4sxzn3ZeT1V0BOPIvppm4xs48iu458u+usKTMbAuQC79PNPkd+CQJp3WnOuZPwdp/dbGanx7ug7i5y+z+df72/x4FjgNHAl8Cv41tO92BmGcDLwI+dc3sav9cdPkd+CYIvgCMaDQ+OjJMI59wXkeftwCt4u9PkQNvM7HCAyPP2ONfTrTjntjnn6pxzYeAJ9DnCzJLwQmCuc+5/IqO71efIL0HwAXCsmQ01s15490aeF+eaug0zSzez3vWvge8Aq6PP5VvzgGsjr68FXotjLd1O/ZdbxPfw+efIzAzv3uzrnHMPNXqrW32OfHNlceQ0tllAAvCUc+6XcS6p2zCzo/G2AsC7j/Wf1T5gZs8BBXjdBm8D7gZeBV4EjsTrDv0y55wvD5i20D4FeLuFHPAZ8M+N9oX7jpmdBrwDfAyEI6P/He84Qbf5HPkmCEREpHl+2TUkIiItUBCIiPicgkBExOcUBCIiPqcgEBHxOQWBSIyZWYGZvR7vOkRaoiAQEfE5BYFIhJldZWbLI/3o/97MEsys3MwejvQlv9DMsiPTjjaz9yKdq71S37mamf2Tmf3VzD40s1Vmdkxk8Rlm9pKZrTezuZErTjGzX0X6qv/IzB6M048uPqcgEAHM7HhgCjDOOTcaqAOuBNKBFc654cBivKtnAeYAtzvnRuFdNVo/fi7wqHPuROBbeB2vgdfr5I/x7odxNDDOzDLxumEYHlnOL2L7U4o0T0Eg4jkLOBn4wMyKIsNH43UL8EJkmj8Bp5lZX6Cfc25xZPwzwOmR/poGOedeAXDOVTnnKiPTLHfOFUc6YysChgClQBXwpJldBNRPK9KlFAQiHgOeaXRnrWHOuXuama6jfbJUN3pdByQ650J4vXO+BJwPvNnBZYscFAWBiGchcImZHQYN95Q9Cu9v5JLINP8PeNc5VwrsMrPxkfFXA4sjd6AqNrPJkWUkm1laSyuM9FHfN3I7x58AJ8biBxNpTWK8CxDpDpxza83s53h3aQsAtcDNQAUwJvLedrzjCOB1Hfy7yBf9ZuD6yPirgd+b2czIMi6NstrewGtmloK3RXJrJ/9YIm2i3kdFojCzcudcRrzrEIkl7RoSEfE5bRGIiPictghERHxOQSAi4nMKAhERn1MQiIj4nIJARMTn/j+JA880VzapdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_oss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "#plt.show()\n",
    "\n",
    "fig = plt.gcf() #변경한 곳\n",
    "#plt.show()\n",
    "fig.savefig('GG.png') #변경한 곳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./image/test/kleague.png', './image/test/seriea.png', './image/test/ligue1.png', './image/test/laliga.png', './image/test/bundesliga.png']\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "caltech_dir = \"./image/test\"\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(caltech_dir+\"/*.*\")\n",
    "for i, f in enumerate(files):\n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    data = np.asarray(img)\n",
    "    filenames.append(f)\n",
    "    X.append(data)\n",
    "print(filenames)\n",
    "X = np.array(X)\n",
    "model = load_model('./model/multi_img_classification.model')\n",
    "\n",
    "prediction = model.predict(X)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000 0.000 0.000 1.000 0.000]\n",
      "3\n",
      "해당 ./image/test/kleague.png이미지는 리그1로 추정됩니다.\n",
      "[0.000 0.000 0.000 0.000 1.000]\n",
      "4\n",
      "해당 ./image/test/seriea.png이미지는 세리에로 추정됩니다.\n",
      "[0.000 0.000 0.000 1.000 0.000]\n",
      "3\n",
      "해당 ./image/test/ligue1.png이미지는 리그1로 추정됩니다.\n",
      "[1.000 0.000 0.000 0.000 0.000]\n",
      "0\n",
      "해당 ./image/test/laliga.png이미지는 라리가로 추정됩니다.\n",
      "[0.000 1.000 0.000 0.000 0.000]\n",
      "1\n",
      "해당 ./image/test/bundesliga.png이미지는 분데스리가로 추정됩니다.\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "#이 비교는 그냥 파일들이 있으면 해당 파일과 비교. 카테고리와 함께 비교해서 진행하는 것은 _4 파일.\n",
    "for i in prediction:\n",
    "    pre_ans = i.argmax()  # 예측 레이블\n",
    "    print(i)\n",
    "    print(pre_ans)\n",
    "    pre_ans_str = ''\n",
    "    if pre_ans == 0: pre_ans_str = \"라리가\"\n",
    "    elif pre_ans == 1: pre_ans_str = \"분데스리가\"\n",
    "    elif pre_ans == 2: pre_ans_str = \"K리그\"\n",
    "    elif pre_ans == 3: pre_ans_str = \"리그1\"\n",
    "    else: pre_ans_str = \"세리에\"\n",
    "        \n",
    "    print(\"해당 \"+filenames[cnt]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    cnt += 1\n",
    "    # print(i.argmax()) #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\n",
    "    # 즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다.\n",
    "    # 이걸 한 것은 _4.py에."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
